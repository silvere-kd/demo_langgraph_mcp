{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b82be6f",
   "metadata": {},
   "source": [
    "# <center>**`Project Details`**</center>\n",
    "\n",
    "#### **Purpose**:\n",
    "\n",
    "Our goal is to showcase how to connect LangGraph agent to an MCP server. The MCP server will expose tools for string analysis, while the client (LangGraph agent) will interact with these tools using Python subprocesses.\n",
    "\n",
    "Here is how the system works:\n",
    "\n",
    " - The MCP server exposes tools to perform arithmetic operations (multiplication and subtraction).\n",
    " - The Client launches the MCP server and creates a session using standard I/O to enable communication between the LangGraph agent and the MCP tools.\n",
    " - The agent loads these tools into its session, intakes the user’s natural language input, and decides whether a tool invocation is needed.\n",
    " - If the agent detects a suitable tool is available, it calls the MCP server through the client and retrieves the result.\n",
    " - The final response is returned to the user in natural language.\n",
    "\n",
    "#### **System Architecture**:\n",
    "\n",
    " 1. **MCP Server**: This component exposes computational tools using FastMCP.\n",
    " 2. **Custom Client using StdioClient**: We’ll implement a Python client using the StdioClient to interact with the server via subprocesses.\n",
    " 3. **LangGraph Agent**: We will build a custom ReAct agent using LangGraph. This agent will receive user’s input, decide whether a tool is needed, and if so, it will automatically load the appropriate tool from the MCP tools running in the connected server session.\n",
    " 4. **Session Communication**: The system uses standard I/O to allow two-way communication between the LangGraph agent and the MCP server.\n",
    "\n",
    "#### **Constraints**:\n",
    "\n",
    " - None\n",
    "\n",
    "\n",
    "#### **Tools**:\n",
    "\n",
    " - Use local **ollama** model\n",
    "\n",
    "#### **Requirements**:\n",
    " - Make it work as expected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7786816a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260bc82",
   "metadata": {},
   "source": [
    "## <center>**`Implementation`**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb31c94b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dc0274d",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442928f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile src/llm/model_params.py\n",
    "# model variables\n",
    "MODEL_URL = \"http://ollama:11434\"\n",
    "MODEL_NAME = \"llama3.2\" # \"qwen3\" # \"mistral\" #\n",
    "MODEL_TEMP = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddfe8d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile src/llm/model_provider.py\n",
    "from langchain_ollama import ChatOllama\n",
    "#from src.llm.model_params import MODEL_URL, MODEL_NAME, MODEL_TEMP\n",
    "\n",
    "def load_model(url:str=MODEL_URL, model_name: str=MODEL_NAME, temperature:float=MODEL_TEMP, **kwargs):\n",
    "    \"\"\"Load local ollama model\"\"\"\n",
    "    return ChatOllama(base_url=url, model=model_name, temperature=temperature, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af1cea7",
   "metadata": {},
   "source": [
    "### ReAct agent in LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cb4da0",
   "metadata": {},
   "source": [
    "#### Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2aa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/agent/state.py\n"
     ]
    }
   ],
   "source": [
    "#%%writefile src/agent/state.py\n",
    "\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c27c1c",
   "metadata": {},
   "source": [
    "#### Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ecc274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/agent/nodes.py\n"
     ]
    }
   ],
   "source": [
    "#%%writefile src/agent/nodes.py\n",
    "#from src.agent.state import AgentState\n",
    "\n",
    "\n",
    "class ChatNode:\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "\n",
    "    async def __call__(self, state: AgentState) -> AgentState:\n",
    "        messages = state['messages']\n",
    "\n",
    "        response = await self.llm.ainvoke(messages)\n",
    "\n",
    "        state['messages'].append(response)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6220b0d2",
   "metadata": {},
   "source": [
    "#### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad61aa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/agent/graph.py\n"
     ]
    }
   ],
   "source": [
    "#%%writefile src/agent/graph.py\n",
    "\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langchain_core.tools import Tool\n",
    "from typing import Optional, List\n",
    "from src.llm.model_params import MODEL_URL, MODEL_NAME, MODEL_TEMP\n",
    "from src.llm.model_provider import load_model\n",
    "from src.agent.nodes import ChatNode\n",
    "from src.agent.state import AgentState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from IPython.display import Image, display\n",
    "\n",
    "class AgentGraph:\n",
    "    def __init__(self, \n",
    "                 llm_model_url: str=MODEL_URL,\n",
    "                 llm_model_name: str=MODEL_NAME,\n",
    "                 ll_model_temp: float=MODEL_TEMP,\n",
    "                 tools:Optional[List[Tool]]=[]):\n",
    "        \n",
    "        llm = load_model(llm_model_url, llm_model_name, ll_model_temp)\n",
    "        self.tools = tools\n",
    "        self.llm = llm.bind_tools(tools) if self.tools else llm\n",
    "        self.chat_node = ChatNode(self.llm)\n",
    "\n",
    "    def graph_builder(self):\n",
    "        graph_builder = StateGraph(AgentState)\n",
    "\n",
    "        # nodes\n",
    "        graph_builder.add_node(\"llm\", self.chat_node)\n",
    "        graph_builder.add_node(\"tools\", ToolNode(tools=self.tools))\n",
    "\n",
    "        # edges\n",
    "        graph_builder.add_edge(START, \"llm\")\n",
    "        graph_builder.add_conditional_edges(\"llm\", tools_condition)\n",
    "        graph_builder.add_edge(\"tools\", \"llm\")\n",
    "\n",
    "        # compile\n",
    "        return graph_builder.compile()\n",
    "    \n",
    "    @property\n",
    "    def graph(self):\n",
    "        if hasattr(self, \"_graph\"):\n",
    "            return self._graph\n",
    "        self._graph = self.graph_builder()\n",
    "        return self._graph\n",
    "    \n",
    "    def display(self):\n",
    "        display(Image(self.graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "    def invoke(self, input:str, config: Optional[RunnableConfig]=None):\n",
    "        return self.graph.invoke(input, config)\n",
    "\n",
    "    async def ainvoke(self, input:str, config: Optional[RunnableConfig]=None):\n",
    "        return await self.graph.ainvoke(input, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcdcba12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = AgentGraph()\n",
    "graph.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7876ac5",
   "metadata": {},
   "source": [
    "#### MCP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1318874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_server.py\n",
    "\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"CalculatorTools\")\n",
    "\n",
    "@mcp.tool()\n",
    "def multiply_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Returns the product of two integers\"\"\"\n",
    "    return a*b\n",
    "\n",
    "@mcp.tool()\n",
    "def subtract_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Returns the difference between two integers\"\"\"\n",
    "    return a-b\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f022ae3",
   "metadata": {},
   "source": [
    "#### MCP client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3c0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_client.py\n"
     ]
    }
   ],
   "source": [
    "#%%writefile mcp_client.py\n",
    "\n",
    "import asyncio\n",
    "from src.llm.model_params import MODEL_URL, MODEL_NAME, MODEL_TEMP\n",
    "from src.agent.graph import AgentGraph\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "model = ChatOllama(base_url=MODEL_URL, model=MODEL_NAME, temperature=MODEL_TEMP)\n",
    "TOOL_ONLY_TASKS = {\"multiply_numbers\", \"subtract_numbers\"}\n",
    "\n",
    "\n",
    "async def main():\n",
    "    server_params = StdioServerParameters(\n",
    "        command=\"python\",\n",
    "        args=[\"mcp_server.py\"]\n",
    "    )\n",
    "\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read_stream=read, write_stream=write) as session:\n",
    "            await session.initialize()\n",
    "\n",
    "            all_tools = await load_mcp_tools(session=session)\n",
    "\n",
    "            strict_tools = [tool for tool in all_tools if tool.name in TOOL_ONLY_TASKS]\n",
    "\n",
    "            agent = AgentGraph(tools=strict_tools)\n",
    "\n",
    "            if strict_tools:\n",
    "                tool_descriptions = \"\\n\".join(\n",
    "                    f\"- {tool.name}: {tool.description}\" for tool in strict_tools\n",
    "                )\n",
    "\n",
    "                system_intruction = (\n",
    "                    \"You are a smart assistant. For general conversation and reasoning, you may use your own thinking.\\n\"\n",
    "                    \"However, for the following operations, you must never calculate by yourself. \"\n",
    "                    \"Always use the tools listed below:\\n\\n\"\n",
    "                    f\"{tool_descriptions}\\n\\n\"\n",
    "                    \"if user asks something that requries other tool, use your own thinking and answer it.\"                    \n",
    "                )\n",
    "\n",
    "                system_message = SystemMessage(content=system_intruction)\n",
    "            else:\n",
    "                system_message = SystemMessage(content=\"You are a helpful assistant. Use your own reasoning freely.\")\n",
    "\n",
    "            print(\"Calculator Assistant is ready. Type 'exit' to quit.\\n\")\n",
    "\n",
    "            while True:\n",
    "                user_input = input(\"You: \").strip()\n",
    "                if user_input.lower() in {\"exit\", \"quit\"}:\n",
    "                    print(\"Exiting...\")\n",
    "                    break\n",
    "\n",
    "                input_messages = [system_message, HumanMessage(content=user_input)]\n",
    "\n",
    "                try:\n",
    "                    result = await agent.ainvoke({\"messages\": input_messages})\n",
    "                    for m in result[\"messages\"]:\n",
    "                        m.pretty_print()\n",
    "                except Exception as e:\n",
    "                    print(\"Error:\", e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec38cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv_gpu_ollama_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
